{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mortality Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File loading method stack overflow link: https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    "#All dataframe methods learned from pandas documentation\n",
    "#np.where learned from numpy documentation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "filename = 'MortalityCondensed.csv'\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "def process_files(local_path):\n",
    "    #Load all .csv files in the mortality directory\n",
    "    all_files = glob.glob(local_path + \"/*.csv\")\n",
    "    dataframe = pd.DataFrame()\n",
    "    file_list = []\n",
    "\n",
    "    for file in all_files:\n",
    "        \n",
    "        df = pd.read_csv(file, index_col = None, header = 0, low_memory = False)\n",
    "        dfInterest = df[['sex','race','detail_age','month_of_death', 'manner_of_death', 'education_2003_revision','education_1989_revision']] #Isolate columns we need\n",
    "        dfInterest['binary_male'] = np.where(dfInterest['sex']=='M', 1, 0)\n",
    "        dfInterest['binary_suicide'] = np.where(dfInterest['manner_of_death']==2, 1, 0) #create the binary suicide column\n",
    "        \n",
    "        #Recode education to get rid of NaNs. Code 18 represents where we have no data.\n",
    "        #dfInterest['education_1989_revision'] = np.where(dfInterest['education_1989_revision'] <= 8, 1, dfInterest['education_1989_revision'])\n",
    "        #dfInterest['education_recode'] = np.where(type(dfInterest['education_2003_revision'])==str, dfInterest['education_1989_revision'], dfInterest['education_2003_revision'])\n",
    "        #dfInterest['education_recode'] = np.where(type(dfInterest['education_recode'])==str, 18, dfInterest['education_recode'])\n",
    "        \n",
    "        #Recode race to give us more meaningful categories 0 hispanic, 1 white, 2 black, 3 asian\n",
    "        dfInterest['binary_white'] = np.where(dfInterest['race'] == 1, 1, 0)\n",
    "        dfInterest['binary_black'] = np.where(dfInterest['race'] == 2, 1, 0)\n",
    "        dfInterest['binary_asian'] = np.where(dfInterest['race'] > 2, 1, 0)\n",
    "        dfInterest['binary_hispanic'] = np.where(dfInterest['race'] == 0, 1, 0)\n",
    "\n",
    "        file_list.append(dfInterest) #add the new dataframe to the list\n",
    "\n",
    "    dataframe = pd.concat(file_list) #concat the whole list to the final dataframe\n",
    "    finaldf = dataframe.drop(columns=['race', 'sex','education_2003_revision','education_1989_revision'])\n",
    "    \n",
    "    # Reordering\n",
    "    finaldf = finaldf[['binary_male', 'binary_white', 'binary_black', 'binary_asian', 'binary_hispanic',\n",
    "                       'detail_age', 'month_of_death', 'binary_suicide']]\n",
    "    finaldf.to_csv(filename)\n",
    "    finaldf.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  binary_male  binary_white  binary_black  binary_asian  \\\n",
      "0           0            0             0             0             1   \n",
      "1           1            0             1             0             0   \n",
      "2           2            0             1             0             0   \n",
      "3           3            1             0             0             1   \n",
      "4           4            0             1             0             0   \n",
      "\n",
      "   binary_hispanic  detail_age  month_of_death  binary_suicide  \n",
      "0                0          68               1               0  \n",
      "1                0          12               1               0  \n",
      "2                0          75               1               0  \n",
      "3                0          61               1               0  \n",
      "4                0          46               1               1  \n"
     ]
    }
   ],
   "source": [
    "# Check if base_file exists\n",
    "# If not, create it\n",
    "if not os.path.isfile(filename):\n",
    "    process_files(\"mortality\")\n",
    "df = pd.read_csv(filename, header=0, encoding='ISO-8859-1')\n",
    "print(df.head())\n",
    "    \n",
    "#print(df.astype(bool).sum(axis=0))\n",
    "\n",
    "# Split into training and test\n",
    "# https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
    "msk = np.random.rand(len(df)) < 0.5\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "Y_train = train.iloc[:,len(train.columns)-1]\n",
    "X_train = train.iloc[:,1:(len(train.columns)-1)]\n",
    "Y_test = test.iloc[:,len(test.columns)-1]\n",
    "X_test = test.iloc[:,1:(len(test.columns)-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Suicide vs Non-Suicide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log_reg_fn = 'log_reg_gridsearch_output.pkl'\n",
    "\n",
    "#alpha_arr = [0.0001,0.001,0.01,0.1,1.0,10.0,100.0]\n",
    "alpha_arr = [0.01]\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for a in alpha_arr:    \n",
    "    classifier = SGDClassifier(loss='log', max_iter=100, tol=1.0e-12, random_state=123, alpha=a)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    # Add to accuracy lists\n",
    "    train_acc.append(accuracy_score(Y_train, classifier.predict(X_train)))\n",
    "    test_acc.append(accuracy_score(Y_test, classifier.predict(X_test)))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(alpha_arr, train_acc, color='blue', lw=2, marker='o', label=\"Training Accuracy\")\n",
    "plt.plot(alpha_arr, test_acc, color='red', lw=2, marker='o', label=\"Testing Accuracy\")\n",
    "\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Alpha vs Accuracy Linear Regression\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "print(train_acc)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output dict just in case\n",
    "# https://stackoverflow.com/questions/19201290/how-to-save-a-dictionary-to-a-filew\n",
    "with open(log_reg_fn, 'wb') as f:\n",
    "    pickle.dump(gs_classifier.cv_results_, f)\n",
    "\n",
    "# Load data\n",
    "log_reg_res = {}\n",
    "with open(log_reg_fn, 'rb') as f:\n",
    "    log_reg_res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_fn = 'svm_gridsearch_output.pkl'\n",
    "\n",
    "# Base svm classifier\n",
    "base_classifier = SGDClassifier(max_iter=1000, tol=1.0e-12, random_state=123)\n",
    "# Define alpha as param to search over\n",
    "svm_alpha_arr = np.asarray([0.0001, 0.001, 0.01, 0.1, 1.0])\n",
    "params = {'alpha': svm_alpha_arr}\n",
    "# Fit to training data, 5 fold CV\n",
    "gs_classifier = GridSearchCV(base_classifier, params, scoring='accuracy', cv=5)\n",
    "gs_classifier.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best parameter settings:\", gs_classifier.best_params_)\n",
    "print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)\n",
    "print(\"Test accuracy: %0.6f\" % accuracy_score(Y_test, gs_classifier.predict(X_test)))\n",
    "\n",
    "# Save output dict just in case\n",
    "# https://stackoverflow.com/questions/19201290/how-to-save-a-dictionary-to-a-filew\n",
    "with open(svm_fn, 'wb') as f:\n",
    "    pickle.dump(gs_classifier.cv_results_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "svm_res = {}\n",
    "with open(log_reg_fn, 'rb') as f:\n",
    "    svm = pickle.load(f)\n",
    "    \n",
    "plt.figure(1)\n",
    "plt.plot(svm_alpha_arr, svm_res['mean_train_score'], color='blue', lw=2, marker='o', label=\"Mean Training Accuracy\")\n",
    "plt.plot(svm_alpha_arr, svm_res['mean_test_score'], color='red', lw=2, marker='o', label=\"Mean Testing Accuracy\")\n",
    "\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Alpha vs Accuracy Linear Regression\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
